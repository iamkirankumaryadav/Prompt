# Prompt Engineering

Crafting ideal inputs to get the most out of LLMs.

1. **Token:** A unit easily understood by a language model.
2. **Tokenization:** The mechanism to split the inputs into tokens.
3. **Completion:** The Language model takes a prompt and creates a completion by constantly predicting the next token.

### GPT

**G:** Generative (Generated data)
**P:** Pre-trained (Trained on a large amount of data)
**T:** Transformer (Language model architecture)

Support multiple modalities (Accept inputs in the form of image, text, audio, video)

